# 算法基础

## 复杂度分析

我们一般使用程序性能来表示一个程序对内存和时间的需求，可以通过性能分析（分析法）和性能测量（实验法）来得到这两个指标。

* 程序运行所需的内存大小：使用 **空间复杂度** 来表示。
* 程序运行所需的时间长短：使用 **时间复杂度** 来表示。

### 渐进记法：大O 表示法

表示的是随数据规模增长的一种变化趋势，一般会忽略低阶、常量以及系数部分。

例如 2n^2 + n + 1 会仅保留 n^2，需要更细致的分析时才会重新分析忽略部分。

* O(1)：常量级。凡事和数据规模无关的都算作常量级。
* O(n)：线性级。
* O(n^m)：m次方级。
* O(logn): 对数级。
* O(nlogn)：线性对数级。
* O(2^n)：指数级。容易膨胀
* O(n!)：阶乘级。容易膨胀

### 空间复杂度

空间复杂度就是表示程序运行所需的内存大小。

* 指令空间：程序指令所占用的存储空间。
* **数据空间**：所有常量和变量所需的空间。
* 环境栈空间：栈中保存的暂停函数和方法恢复运行所需要的信息。
  * 使用递归时可能需要考虑这部分空间。

进行分析时 一般可以忽略 指令空间和 环境栈空间，只需要考虑受规模影响的那部分数据即可。

### 时间复杂度

时间复杂度用于表明程序运行所需要等待时间。

程序的执行时间和具体数据类型的操作有关，不同的操作间的耗时并不相同。不过进行分析时 一般会假设每行代码的执行时间相同，从而统计代码执行的行数即可。

> 在小规模数据面前, O(n2) 时间复杂度的算法并不一定比 O(nlogn) 的算法执行时间长。因为此时省略的低阶、系数和常数的影响将会放大。

### 最好、最坏、平均时间复杂度

程序运行时执行流程会收到一些条件语句影响，从而出现在不同条件下时间复杂度会不相同。

此时一般会分析最好、最坏、平均三种场景下的时间复杂度。

* 最好：最理想条件下的时间复杂度。最短时间
* 最坏：最坏条件下时间复杂度。最长时间。
* 加权平均：平均情况分析比较复杂，需要从概率统计方面进行计算。

### 均摊分析

将个别时间复杂度较高的情况分摊到其他时间复杂度较的场景，一般情况下和最好时间复杂度相同。

* 大部分场景下复杂度都较低，个别情况复杂度较高。
* 存在一定的规律，前后连贯的时序关系。



## 有序度和逆序度

* 有序度：表示一组数据的有序程度。将队列中每个数后面比当前数小的数的个数之和。
* 逆序度：表示一组数据的无序程度。
* 完全有序/完全逆序 计算公式：n(n-1)/2

例如  `1、2、3`。

有序度：3；完全有序：2 + 1 + 0;（1，2）（1，3）（2，3）

逆序度：0

例如  `1、2、5、3`。

有序度：5；（1，2）（1，5）（1，3）（2，5）（2，3）

逆序度：1；有 (5，3) 

## 算法思想

算法 是用于解决某个问题的，而一个问题可以分为目标、决策约束条件这几个部分。
* **目标**：就是我们的期望值，问题的最优结果。
* **约束条件**：一些无法避免，必须遵循的条件，我们所有的决策都受到这些条件的约束。
* **决策**：在解决问题过程我们会做出一个个决策，当然这些决策受约束条件的影响，最终解决这个问题。 可以对应到 算法思想。

整个问题的解决过程就是，首先给定数据，然后在一定条件的约束下，采取一定的决策得到目标值。

其中条件无法改变，目标也是确定的，一般是最大、最小或给定的明确值。决策是这个过程的变量，决策的好坏就决定了整体的好坏。

### 枚举/穷举

> 解空间：该问题所有可行/不可行解的集合

枚举就是在 解空间中 全局遍历找出最优解，**穷举所有的可能组合求出所有候选答案，并从这些候选答案中取选择正确的结果，枚举法得到的一定是最优解**。当然前提是候选答案是能够确定的。

存在的问题：

* 就是随着数据规模的上升，解空间 会急剧膨胀，从而导致时间复杂度快速上升。

### 贪心

**贪心的核心思想就是 每次都选出当前情况下的最优解，保证局部最优，从而一步步推导出全局最优**，速度快，和数据规模时线性关系。

相比于枚举，**贪心并不能保证一定是全局最优解，有时可能还是最坏解，不太稳定**，主要是由于前一个选择会影响后面的选择。

贪心有点竭泽而渔的意思，当前能收获很多，但是之后就没有鱼能够捕获了，反而得到了最坏的结果。

对于那些 存在限制条件 求 期望值的场景，往往可以使用贪心思想来处理：

* 01背包问题
* 分糖果
* 霍夫曼编码 Huffman Coding
* Prim 和 Kruskal 最小生成树算法
* Dijkstra 单源最短路径算法



### 分治

分治的核心思想就是 分而治之。将一个大问题划**分解**为多个结构相同彼此独立的小问题，可以递归来**处理**这些小问题，得到各自结果后进行**合并**，得到最终结果。

* 原问题可以被分解成具有相同模式的子问题。
* 子问题可以单独求解，且彼此独立。
* 存在边界值，不会出现无限分解的情况。
* 子问题可以合并回原问题，且合并操作复杂度较低。

### 回溯

时间复杂度：指数级很高，O(2^n)。

空间复杂度：

结合 备忘录，用空间换时间可以去除重复计算降低时间复杂度，接近动态规划。



### 动态规划

动态规划用于解决最优问题（最小、最大），使用动态规划的前提

* **最优子结构**：问题的最优解包含子问题的最优解；后面阶段的状态可以通过前面阶段的状态推导出来。
* **无后效性**：子问题的状态确定后，不会受后面阶段的影响。
* **重复子问题**：不同的决策序列，到达某个阶段后，可能会产生重复的状态。

一般步骤：

* 推导状态转移方程。
* 定义一个 `dp` 状态数组，记录各个阶段的状态。
* 编码

时间复杂度：O(n*w)

空间复杂度：O(n*w)，部分动态规划空间复杂度可以进行优化。

```kotlin
/**
 * 最小路径和
 * 给定一个包含非负整数的 m x n 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。
 * 每次只能向下或者向右移动一步
 */
class Solution {

    /**
     * 动态规划
     * 
     * f[i][j] = f[i - 1][j] || f[i][j - 1] + 当前路径长度
     * 时间复杂度：O(mn)
     * 空间复杂度：O(mn)
     */
    fun minPathSum(grid: Array<IntArray>): Int {
        if (grid.isEmpty()) return 0
        val m = grid.size // 行
        val n = grid[0].size // 列
        val dp = Array(m) {
            IntArray(n)
        }
        //初始化左上角
        dp[0][0] = grid[0][0]
        // 初始化第一列(每行第一个元素)，只能从上边演变过来
        for (i in 1 until  m) {
            dp[i][0] = grid[i][0] + dp[i - 1][0]
        }
        // 初始化第一排 (每列第一个元素)，只能从左边列演变过来列状态
        for (j in 1 until n) {
            dp[0][j] = grid[0][j] + dp[0][j - 1]
        }
        // 处理其他元素
        for (i in 1 until m) {
            for (j in 1 until n) {
                // 只能下、右移动，所以 当前状态只可能从 上边 或者 左边得到
                // 当前路径值 + min(上方最小路径，左边最小路径)
                dp[i][j] = grid[i][j] + Math.min(dp[i - 1][j], dp[i][j - 1])
            }
        }
        return dp[m - 1][n - 1]
    }
}
```

### 启发式

启发式的思想是在一个合理的资源(时间、空间)范围内，求得一个比较优质的解，一般优于贪心的解，可能达到最优解，

#### 邻域搜索

基本思路：

1. 确定一个初始解。
2. 根据初始解 划定一个 邻域(局部解空间)
3. 比较邻域中的解，选取更好的。这里有两种方式，一种是找到好的就直接更新，还有一种是遍历选取最好的一个。
4. 根据3的得到的解，重新计算邻域。
5. 重复3，4，知道满足终止条件就退出。

> 陷入局部最优解时，即邻域内其他解都比当前差，或者多次移动后回到同一个解。此时需要跳出这个区域来求解，这个过程叫做 **扰动（shake、perturbation）**

#### 群体仿生



---

## 排序算法

> 原地排序：空间复杂度为O(1)的排序算法。
>
> 稳定排序：原序列中值相等的元素，排序后先后顺便没有改变。

| 排序算法 | 时间复杂度                  | 空间复杂度 | 原地排序？ | 稳定排序？ | 使用场景                   |
| -------- | --------------------------- | ---------- | ---------- | ---------- | -------------------------- |
| 冒泡排序 | O(n^2)                      | O(1)       | Y          | Y          |                            |
| 插入排序 | O(n^2)                      | O(1)       | Y          | Y          |                            |
| 选择排序 | O(n^2)                      | O(1)       | Y          | N          |                            |
| 归并排序 | O(n logn)                   | O(n)       | N          | Y          |                            |
| 快速排序 | O(n logn), 最坏退化为O(n^2) | O(1)       | Y          | N          | Java中的的 `Arrays.sort()` |
| 桶排序   | O(n)                        | O(n)       | N          | Y          |                            |
| 计数排序 | O(n + k)，k是数据范围       | O(m)       | N          | Y          |                            |
| 基数排序 | O(d n), d是维度             |            | N          | Y          |                            |
| 堆排序   | O(nlogn)                    |            |            |            |                            |

### 冒泡排序（Bubble Sort）

基于比较，是一种稳定排序。

* 顺序遍历元素，依次进行冒泡。
* 每次冒泡都比较前后每个元素，**若前一个大于后一个则进行交换**。
  * 每次冒泡可以确定一个值的位置，所以操作次数依次递减。
* 当遍历到数组末尾或者某个元素冒泡操作未发生交换则完成排序。

复杂度分析：

* 时间复杂度 O(n^2)，元素交换次数固定等于逆序度。

  * 最好:O(n)

  * 最坏:O(n^2)

* 空间复杂度 O(1)

```kotlin
		/**
     * 冒泡排序
     * [compare]：指定比较方式，默认降序输出
     */
    fun bubbleSort(arrays: IntArray, compare: (Int, Int) -> Boolean = { f, s -> f > s }): IntArray {
        // 倒序遍历：表示需要比对的次数
        for (end in (arrays.size - 1) downTo 1) {
            // 顺序遍历：进行比对
            for (begin in 0 until end) {
                if (compare(arrays[begin], arrays[begin + 1])) {
                    // 默认为前一个大于后一个，交换
                    val temp = arrays[begin]
                    arrays[begin] = arrays[begin + 1]
                    arrays[begin + 1] = temp
                }
            }
        }
        return arrays
    }
```

### 插入排序（Insertion Sort）

基于比较，是一种稳定排序。

* 将数组分为已排序区和未排序区，一开始已排序区为空，未排序区就是整个数组。

* 顺序遍历未排序区，**和已排序区元素进行比较，找到合适的位置插入**，并将插入点的数据迁移。
  * 迁移操作可以在遍历比对的过程中同步进行。
* 当未排序区为空完成排序。

复杂度分析

* 时间复杂度 O(n^2)，元素移动次数固定等于逆序度。

  * 最好:O(n)

  * 最坏:O(n^2)

* 空间复杂度 O(1)

```kotlin
/**
     * 插入排序，降序输出
     */
	fun insertionSort(arrays: IntArray): IntArray {
        if (arrays.size <= 1) return arrays
        for (i in 1 until arrays.size) {
            val value = arrays[i]
            // 进行向前比较，查找到插入的位置，即 <= value的前一个位置
            // j 指向比较位置
            var j = i - 1
            while (j >= 0) {
                // 若value小于前面的值，则暂时记录 作为插入位置。
                // 同时搬移数据
                if (value < arrays[j]) {
                    arrays[j + 1] = arrays[j]
                } else { // 当前 j位置的值 <= value，跳出循环
                    break
                }
                --j
            }
          	// 当前 arrays[j] <= value
          	// 插入j的后面
            arrays[j + 1] = value
        }
        return arrays
    }
```

### 选择排序（Selection Sort）

也是基于比较，类似插入排序，但它是一种不稳定排序算法。

* 将数组分为已排序区和未排序区，一开始已排序区为空，未排序区就是整个数组。

* 遍历未排序区，**选择出最小值，插入到已排序区末尾**（即和未排序区队首交换）。
* 当未排序区为空完成排序。

复杂度分析：

* 时间复杂度 O(n^2)

  * 最好:O(n)

  * 最坏:O(n^2)

* 空间复杂度 O(1)

```kotlin
	fun selectionSort(arrays: IntArray): IntArray {
        if (arrays.size <= 1) return arrays
        for (i in arrays.indices) {
            val minIndex = getMinIndex(arrays, i, arrays.size - 1)
            // 和最小值进行交换
            val temp = arrays[i]
            arrays[i] = arrays[minIndex]
            arrays[minIndex] = temp
        }
        return arrays
    }

    private fun getMinIndex(arrays: IntArray, start: Int, end: Int): Int {
        var minIndex = start
        for (i in (start + 1)..end) {
            if (arrays[i] < arrays[minIndex]) {
                minIndex = i
            }
        }
        return minIndex
    }
```



### 归并排序（Merge Sort）

核心是**分治思想**。是否是稳定算法取决于 `merge()`函数，下面代码中是稳定算法。

归并排序整个流程是**自底向上**的：

* 将一个大问题**直接分解**为一个个子问题处理，直到不可分割。 此时各个子问题间是无序的
* 优先**处理子问题进行排序**，然后再向上合并，最终得到结果。

复杂度分析：

* 时间复杂度 O(nlogn)

* 空间复杂度 O(n)

```kotlin
/**
     * 归并排序，从小到大 升序输出
     */
    fun mergeSort(arr: IntArray): IntArray {
        if (arr.size <= 1) {
            return arr
        }
        return actualMergeSort(arr, 0, arr.size - 1)
    }

    /**
     * 递归执行
     */
    private fun actualMergeSort(arr: IntArray, start: Int, end: Int): IntArray {
        if (start > end) {
            return intArrayOf()
        }
        if (start == end) {
            return intArrayOf(arr[start])
        }
        val mid = (start + end) / 2
        return merge(actualMergeSort(arr, start, mid), actualMergeSort(arr, mid + 1, end))
    }

    /**
     * 合并两个有序数组
     */
    private fun merge(arr1: IntArray, arr2: IntArray): IntArray {
        if (arr1.isEmpty()) return arr2
        if (arr2.isEmpty()) return arr1
        val retArr = IntArray(arr1.size + arr2.size)
        var p1 = 0
        var p2 = 0
        var num1: Int
        var num2: Int
        while (p1 < arr1.size || p2 < arr2.size) {
            num1 = if (p1 < arr1.size) arr1[p1] else Int.MAX_VALUE
            num2 = if (p2 < arr2.size) arr2[p2] else Int.MAX_VALUE
            retArr[p1 + p2] = if (num1 <= num2) {
                p1++
                num1
            } else {
                p2++
                num2
            }
        }
        return retArr
    }
```


###  快速排序（Quick Sort）

> Java 的 `Arrays.sort()` 就是快速排序。

核心思想就是也是分治，类似归并排序，分区操作则是有点选择排序的意思。和归并排序的主要区分是，归并是直接分解，子问题排序后再合并得到结果，快速排序则是在分区操作中确定了顺序，分区完后就直接有序了并不需要合并。

* 对于数组[p, r]，首先选择某个分区点 pivot。遍历数组[p, r]，将小于 pivot的放在左边，大于pivot 的放在右边。
* 得到左右两个分区以及分区点pivot三个部分。
* 不过左右分区并不是有序的，需要继续递归处理左右分区的数据。
* 递归结束就得到排序结果。

复杂度分析：

* 时间复杂度 O(nlogn)，在极端情况下分区极其不均匀会退化为 O(n^2)，不过大部分情况依然是O(nlogn)。

* 空间复杂度 O(1)

> 分区选择优化

* 三数取中法；

  首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。数组比较大时，取数需要更多，5数、10数等。

* 随机法；

  随机选择一个元素作为分区点，每次都选中最差分区的情况不太可能出现。

> 递归优化

* 限制递归层级；

* 自己实现堆上栈；手动模拟递归，越过系统栈大小的限制；


```kotlin
		/**
     * 快速排序，不稳定排序算法
     */
    fun quickSort(arr: IntArray): IntArray {
        return actualQuickSort(arr, 0, arr.size - 1)
    }

    /**
     * 递归执行
     */
    private fun actualQuickSort(arr: IntArray, start: Int, end: Int): IntArray {
        if (start > end) {
            return intArrayOf()
        }
        if (start == end) {
            return intArrayOf(arr[start])
        }
        val pivot = partition(arr, start, end)
        actualQuickSort(arr, start, pivot - 1)
        actualQuickSort(arr, pivot + 1, end)
        return arr
    }

    /**
     * 分区函数，分区并返回分区点
     */
    private fun partition(arr: IntArray, start: Int, end: Int): Int {
        // 内部使用类似选择排序的方式进行分区、比对、交换
        // 获取分区操作的分区比较点
        val pivot = makePivot(arr, start, end)
        var i: Int = start // 指向已分区插入节点位置
        for (j in start..end) {
            if (arr[j] <= pivot) {
                // <= pivot，加入到已分区末尾
                // 交换
                swap(arr, i, j)
                if (j != end) {
                    // 不是最后一位，就后移一位
                    // 遍历到最后时，必然等于pivot，此时交换即可，且i就是分区点
                    i++
                }
            }
        }
        return i
    }

    /**
     * 获取分区操作的分区比较点。
     * 1. 直接获取最后一个
     * 2. 三数取中，根据start、mid、end，选取中间大小的数字作为分区点，将中数放到最后即可
     * 3. 随机
     */
    private fun makePivot(arr: IntArray, start: Int, end: Int): Int {
        if (start - end <= 1) {
            return arr[end]
        }
        val mid = (start + end) / 2
        // 1
        if (arr[start] > arr[mid]) {
            swap(arr, start, mid)
        }
        // 2, 此时 start最小
        if (arr[start] > arr[end]) {
            swap(arr, start, end)
        }
        // 若 mid 为中数，所以后end交换
        if (arr[mid] < arr[end]) {
            swap(arr, mid, end)
        }
        return arr[end]
    }

    private fun swap(arr: IntArray, i: Int, j: Int) {
        val temp = arr[i]
        arr[i] = arr[j]
        arr[j] = temp
    }
```

### 桶排序（Bucket sort）

遍历n个数据并均匀的划分到 m 个有序的桶中，然后每个桶内部使用快排单独排序，最后依次从桶中取出数据，这样就有序了。

复杂度分析：

* 时间复杂度：O(n)；
  * 数据遍历划分： O(n)
  * m次桶内排序：k=n/m; m* klogk; 当 m 和n 相近时 logk是很小的常数。
* 空间复杂度：O(n)

使用桶排序的条件：

* 数据容易划分，数据范围较小。
* 桶间数据比较均匀。
* **适用于外部排序：数据存储在磁盘中，数据量大，但是内存有限，无法全部加载的情况**。

### 计数排序（Counting sort）

特殊的桶排序，相当于分组。每个桶表示一个值，桶内的元素没有先后关系，且这里存储的是元素个数不是具体的值，直接存储即可，节省了桶内排序的时间。

* 确定数据范围：遍历元素，查询最大、最小值计算范围。
  * 这里还需要将 max、min转为数组下标。即

* 将数据映射到数组中[0, max - min]，并计数：遍历元素并进行计数。例如 a[0] = 2，表示存在2个值为0元素。
  * [0,1,2,0,1,2,2] 转为 [2,2,3]
  * [ -1, -1, 1] 转为 [2,0,1]
* 完成计数后，对内部计数进行累加。
  * [2,2,3]  转化为 [2, 4, 7]。即。<=2的数有7个。
* 累加后其实我们就得到了每个元素对应的在元素数组中的左右边界。
  * [2,4,7] 对应 0~1; 2~3; 4~6
* 转换填充完成后就完成排序。
  * 最终得到  [0,0,1,1,2,2,2] 这样的排序结果

复杂度分析：

* 时间复杂度：O(n)
* 空间复杂度：O(m)；m表示数据范围 max - min。
  * 适用于**数据范围小于数据量**的场景。原因就是一个值就需要划分一个桶，无论原数据中是否存在这个值。例如就两个值(0, 100000)，此时用计数排序 需要申请 100001个桶，很浪费。



### 基数排序（Radix sort）

按 **位** 进行排序，需要保证排序算法的稳定性且是线性排序（桶排序、计数排序）。使用于多维度条件的排序。

复杂度分析：

* 时间复杂度：O(d*n)，d指维度。

### 堆排序（Heap sort）

堆排序就是使用 **堆** 的特性来进行排序。 时间复杂度 O(nlogn)

```kotlin
class Heap(
    capacity: Int
) {
    private val data: IntArray
    private val n: Int // 最大数据容量

    var count: Int
        // 已存储数据个数
        private set

    init {
        // 数组 data[0] 第一个位置不存储数据，方便后续计算。
        data = IntArray(capacity + 1)
        n = capacity
        count = 0
    }

    fun insert(value: Int) {
        if (count >= n) return
        count++
        data[count] = value
        maxHeapify(count / 2)
    }

    fun removeTop() {
        // 将根节点和最后一个叶子节点交换，并删除
        swap(1, count)
        count--
        maxHeapify(count / 2)
    }

    fun getTop(): Int {
        if (count == 0) return -1
        return data[1]
    }

    /**
     * 堆化: 大顶堆
     * [node]：非叶子节点
     */
    private fun maxHeapify(node: Int) {
        if (count <= 0 || node < 1) return
        var i = node
        while (i > 0) {
            val left = i * 2
            val right = i * 2 + 1
            var largest = i
            if (left <= count && data[left] > data[largest]) {
                largest = left
            }
            if (right <= count && data[right] > data[largest]) {
                largest = right
            }
            swap(i, largest)
            i /= 2
        }
    }

    private fun swap(i: Int, j: Int) {
        val temp = data[i]
        data[i] = data[j]
        data[j] = temp
    }
}
```



## 拓扑排序

实现方式：

* Kahn算法：贪心算法，代码形式类似BFS
  * 统计所有节点的入度。
  * 依次遍历入度为0的节点，并输出。仅0才会输出。
  * 环检测：输出的节点少于总节点数，最终还存在入度不为0的节点。表示存在环。
* DFS深度优先搜索算法：
  * 

常见的应用场景：

* 确定源代码的编译依赖关系。
* 检查图是否存在环。



---

## 查找算法

| 算法     | 时间复杂度 |      |
| -------- | ---------- | ---- |
| 二分查找 | O(logn)    |      |
|          |            |      |
|          |            |      |

### 二分查找（Binary Search）

> 在链表中的`跳表`可以支持类似二分的查找算法

折半查找算法

* 顺序表结构
* 有序数据集合

时间复杂度：O(logn)

> 二分查找变形问题

* 查找第一个值等于给定值的元素
* 查找最后一个值等于给定值的元素
* 查找第一个大于等于给定值的元素
* 查找最后一个小于等于给定值的元素

### 广度优先搜索（Breadth-First-Search）

使用队列的方式实现，利用先进先出的特性。

> 路径求和为例：查询树中 是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 `targetSum`。

```kotlin
/**
     * BFS，使用队列，先进先出
     * 时间复杂度：O(n)
     * 空间复杂度：O(n)
     */
    fun hasPathSum(root: TreeNode?, targetSum: Int): Boolean {
        root ?: return false
        if (root.left == null && root.right == null) {
            return targetSum == root.`val`
        }

        val queue = LinkedList<TreeNode?>()
        // 记录当前节点对应对应的 sum值
        val sumQueue = LinkedList<Int>()
        // 添加到末尾
        queue.add(root)
        sumQueue.add(root.`val`)
        while (queue.isNotEmpty()) {
            // 获取第一个元素
            val node = queue.poll()
            val sum = sumQueue.poll() ?: 0
            if(node?.left == null && node?.right == null && sum == targetSum) {
                // 遍历到这个叶子节点时，sum == targetSum
                return true
            }
            // 从队首获取数据，先添加左 就先处理, 后添加右，后处理
            node?.left?.let {
                queue.add(it)
                sumQueue.add(sum + it.`val`)
            }
            node?.right?.let {
                queue.add(it)
                sumQueue.add(sum + it.`val`)
            }
        }
        return false
    }
```



### 深度优先搜索（Depth-First-Search）

深度优先的实现方式有递归或栈。两者其实是相同的，递归使用的程序的调用栈，所以本质上没什么区别，利用的就是后进先出。

> 路径求和为例：查询树中 是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 `targetSum`。

```kotlin
    /**
     * 递归,DFS
     * 时间复杂度：O(n)
     * 空间复杂度：O(logn)，树的高度，最坏可能是 O(n)，树呈现为链状。
     */
    fun hasPathSum(root: TreeNode?, targetSum: Int): Boolean {
        root ?: return false
        if (root.left == null && root.right == null) {
            return targetSum == root.`val`
        }
        return hasPathSum(root.left, targetSum - root.`val`)
                || hasPathSum(root.right, targetSum - root.`val`)
    }
```

使用栈实现时，和 BFS 的实现代码很相似。利用后进先出的方式实现。

```kotlin
/**
     * DFS, 利用栈，后进先出的特性
     * 这里使用 LinkedList 实现, push 和 pop 是和 Stack 一样的，
     * 时间复杂度：O(n)
     * 空间复杂度：O(n)
     */
    fun hasPathSum3(root: TreeNode?, targetSum: Int): Boolean {
        root ?: return false
        if (root.left == null && root.right == null) {
            return targetSum == root.`val`
        }
        val queue = LinkedList<TreeNode?>()
        // 记录当前节点对应对应的 sum值
        val sumQueue = LinkedList<Int>()
        queue.push(root)
        sumQueue.push(root.`val`)
        while (queue.isNotEmpty()) {
            // 获取队首
            val node = queue.pop()
            val sum = sumQueue.pop()
            if(node?.left == null && node?.right == null && sum == targetSum) {
                // 遍历到这个叶子节点时，sum == targetSum
                return true
            }
            // 先添加到队首
            node?.right?.let {
                queue.push(it)
                sumQueue.push(sum + it.`val`)
            }
            // 后添加到队首，优先处理左节点
            node?.left?.let {
                queue.push(it)
                sumQueue.push(sum + it.`val`)
            }
        }
        return false
    }
```



---

## 哈希算法

> 将任意长度的二进制值串映射为固定长度的二进制值串。

### 哈希算法的要求

* **单向推导：**从哈希值不能反推出原始数据（也叫单向哈希算法）。
* **数据敏感**：对于不同的输入数据，哪怕仅相差一个Bit，得到的哈希值也大不相同。
* **散列冲突概率低**：鸽巢原理
* **高效执行：**针对大量文本也能快速的计算出哈希值。

### 哈希算法的应用

* 安全加密：例如 **MD5**（MD5 Message-Digest Algorithm，MD5 消息摘要算法）、**SHA**（Secure Hash Algorithm，安全散列算法）、**DES**（Data Encryption Standard，数据加密标准）、**AES**（Advanced Encryption Standard，高级加密标准）等。
* 唯一标识：例如图库搜索图片
* 数据校验
* 散列函数：偏向于数据的平均性和执行效率。
* 负载均衡：客户端IP计算哈希，并根据服务器数量取模分配。
* 数据分片：使用哈希对海量数据进行分片，多机分布式处理。类同负载均衡。
* 分布式存储：一致性哈希算法。

### 一致性哈希算法

> 背景：在分布式缓存中，我们通过取模的方式将哈希值分布到不同服务器上，若此时需要进行扩容/缩容时，所有数据都需要重新计算哈希值。
>
> 那么就会导致所有数据请求都会穿透缓存，直接请求数据库，可能出现雪崩效应，压垮数据库。

一致性哈希算法通过将**数据的哈希划分为n个区间（尽可能大）**，并将这些区间分配给m台设备管理，**每台负责`n/m`个区间**。当有新的设备加入时，只需要**将部分区间数据搬迁到新的设备**即可，不需要全部重新哈希计算。



## 字符串匹配算法

常见的字符串匹配算法有 BF、RK、BM、KMP、AC 自动机、Trie等。

### BF（Brute Force）

> 暴力匹配算

算法思路就是主串和模式串直接一位位的进行匹配。

时间复杂度： O(n*m)，n 主串长度，m模式串长度。

### RK

算法思路：

1. 计数主串中所有长度为m的子串, m是 模式串的长度。
2. 计数模式串的哈希值和这些子串进行匹配。哈希值相同则匹配。

哈希算法的设计思路 ：

根据字符范围设计 K 进制，通过进制换算计算出 子串的值。例如 a~z 对应 0~25

`abc = 0*26*26 + 1 * 26 + 2` 。

由于连续的子串间存在一定联系，可以在一次遍历中快速的计算出所有子串的哈希值。





### BM算法

* **主串**：匹配过程中被匹配的内容，在这些内容中匹配查找我们需要的字符串。
  * 在字符串 `abcabd` 中查找 `abd`。即`abcabd` 就是主串
* **模式串**：匹配过程中我们需要匹配查找的内容。
  * 在字符串 `abcabd` 中查找 `abd`。 `abd`就是模式串。
* **坏字符**：从后面开始不能匹配的字符。
  * 例如匹配到 `abc` 和 `abd`时 `c`、`d` 就是坏字符。

* **好前缀**：模式串和主串匹配过程中已经匹配的那些字符串。
  * 例如匹配到 `abc` 和 `abd`时 `ab`就是好前缀
* **好后缀**：坏字符后面那端匹配的字符串。
  * 例如在字符串 `abcad` 中查找 `abdad`。后面的`ad` 就是好后缀。

### KMP算法

若模式串中存在 前n个字符 = 后n个字符，例如在模式串`b[0, i]` 中存在 `b[0, i - n]` = `b[n, i]`。

名词概念：

* **前缀子串**：`b[0, i - n]` 
* **后缀子串**： `b[n, i]`
* **最长可匹配后缀子串**：好前缀的所有后缀字串中，最长的那一个。
* **最长可匹配前缀子串**：最长可匹配后缀子串，对应的前缀子串。
* **失效函数（next数组)**：存储的是 模式串 中每个前缀的最长可匹配前缀字串的结尾字符下标。
  * 例如 `ababc`。就会包括 `a`、`ab`、`aba`、`abab` 三个，指分别为 -1、-1、0、1。下标
  * -1表示不存在最长可匹配前缀字串。0是a的字符下标。1是b的字符下标


结论1：

假设 `b[0, i]` 的最长可匹配后缀字串是 `b[r, i]`，也就是说`b[0, i - r]` = `b[r, i]`。

那么它们各去除末尾相同位数后应该还是相等的，即`b[0, i - r - 1]`  = `b[r, i - 1]`。

且 `b[r, i - 1]` 是 `b[0, i - 1]` 的其中一个后缀子串。

* 若之前 `b[i - r] = b[i] ` 则 `b[r, i - 1]` 是  `b[r, i - 1]` 的最长可匹配后缀子串。否则就不一定是最长。



## 最短路径算法

### Dijkstra

用于求有向图中单个源点到其他顶点的最短路径，利用贪心思想。

```kotlin
// 记录从 源点 到 i 的最短距离
vertex = vertexs[i]
// queue 优先级队列，保证每次先从 距离源点 最近的顶点延展到其他顶点，保证出队顶点已经是最短路径。
// bfs 处理 和顶点 i 相连的所有边 edge，层层向下。
// edge.id 的最短路径
nextVertex = vertexs[edge.id]
// 选取最小
vertex.dist = minOf(vertex.dist + edge.weight, nextVertex.dist)
```



### Floyd

右称为插点法，用于解决多源最短路径问题。

```kotlin
// mp[i][j] 记录两点间的最短路径
// 插点 k, 比较 i -> j 和 i -> k + k -> j
mp[i][j] = minOf(mp[i][j], mp[i][k] + mp[k][j])
```



## 编码

### 定长编码

每个编码都使用的相同位数表示。

### 前缀编码（前缀树）11

对字符集进行编码时，要求字符集中的任意字符的编码都不是其他字符编码的前缀。

使用前缀树来表示，根节点不包含字符，从根节点到叶子节点的每条路径都代表一个唯一编码，它们的长度也可能是不同的。

### 哈夫曼编码（哈夫曼树）

哈夫曼编码不仅考察 存在多少不同字符编码， 还会考察字符出现的频次。

* 频次高的编码长度短，频次低的长度长。

哈夫曼树是一种 最优二叉树。

组建过程：

1. 将所有字符根据出现频次的高低放到优先级队列中。

2. 从优先级队列中取出 两个 最低频率的字符 A, B，组合成节点C，值为 AB频率之和。C作为 AB的父节点。

3. 将C放会优先级队列，重复第二步。直至队列为空。



## 数据类型对应空间大小

一个内存地址 `0xFF` 代表 一个字节（8bit）

> 常见的 b 和 B的区别，B指 字节byte，b值 位bit

| 单位       | 大小                  |                                                  |
| ---------- | --------------------- | ------------------------------------------------ |
| bit：位    | 可以表示 0和1。       | 计算运行的基本单位。                             |
| byte：字节 | 1byte = 8bit          | 文件大小的基本单位。读取的文件流就是byte为单位。 |
| word：字符 | 1字符 = 2byte = 16bit | 英文字母：1字符；中文字符：2字符。               |
|            |                       |                                                  |



### Java

> n 表示数据类型的 位数
>
> 一般取值范围计算：[-2^(n -1), 2^(n-1)-1]
>
> 若是无符号：[0, 2^n -1]

| 类型      | 字节 | 位数 | 默认值  | 取值范围                                    |
| :-------- | :--- | :--- | :------ | ------------------------------------------- |
| `byte`    | 1    | 8    | 0       | [-128, 127]                                 |
| `short`   | 2    | 16   | 0       | [-32768, 32767]                             |
| `char`    | 2    | 16   | 'u0000' | [0, 65535]                                  |
| `int`     | 4    | 32   | 0       | [-2147483648, 2147483647]                   |
| `long`    | 8    | 64   | 0L      | [-9223372036854775808, 9223372036854775807] |
| `float`   | 4    | 32   | 0f      | 1.4E-45 ~ 3.4028235E38                      |
| `double`  | 8    | 64   | 0d      | 4.9E-324 ~ 1.7976931348623157E308           |
| `boolean` |      | 1    | false   | true、false                                 |



循环不变式

> 元素A[1..j-1]就是原来在位置1到j-1的元素，但已按序排列

- 初始化：循环的第一次迭代之前，它为真。
- 保持：如果循环的某次迭代之前它为真，那么下次迭代之前它仍为真。
- 终止：在循环终止时，不变式为我们提供一个有用的性质，该性质有助于证明算法时正确的。

