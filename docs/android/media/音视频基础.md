# 音视频基础

---

[TOC]



## 音视频生成流程

* 摄像机 和 录音设备分别进行数据采集。
* 然后将数据送入对应的编码器。
* 将编码得到的音轨和视轨送入到合成器（FFmpeg 等），最终合并成MP4文件。

![406204beab2de273ecdb436d4bf66773](./%E9%9F%B3%E8%A7%86%E9%A2%91%E5%9F%BA%E7%A1%80.assets/406204beab2de273ecdb436d4bf66773.webp)

| 基础概念  | | |
| :--- | :---- | :---- |
| 模拟信号（Analog signal） | 是指用连续变化的物理量表示的信息，即时间上和数值上均连续的信号。 | 例如温度传感器反应的温度变化的电信号。 |
| 数字信号（Digital Signal） | 将模拟信号数字化（A/D变化）后得到的离散的值。 | |
| - | | |
| 音调（音频） | 低音：音频慢<br/>高音：音频快                                |                                                              |
| 音量         | 振动的幅度                                                   |                                                              |
| 音色(音品)   | 和材质有关，本质是谐波                                       |                                                              |
| 音轨         |                                                              | AAC                                                          |
| 视轨         |                                                              | H.265(HEVC)、H.264                                           |
| -            |                                                              |                                                              |
| 响度级（方） | 人对声音大小的感觉                                           |                                                              |
| 声压级等同分贝(dB) | 声音测量最常用的物理量是声压，它是声音对单位面积的压强。人耳可听的声压范围为2×10^-5Pa~20Pa，为了方便表示引入了分贝的概念，对应的声压级范围为0~120dB。 | 超过90dB会损害人耳。 |
| -            |                                                              |                                                              |
| 吸音         | 解决声音反射而产生的嘈杂感，吸音材料可以衰减入射音源的反射能量，从而达到对原有声源的保真效果。 | 比如录音棚里面的墙壁。                                       |
| 隔音         | 解决声音的透射而降低主体空间内的吵闹感，隔音棉材料可以衰减入射音源的透射能量，从而达到主体空间的安静状态。 | 比如KTV里面的墙壁。                                          |
| 回声         | 回声是因为声音在传播过程中遇到障碍物会反弹回来。             |                                                              |
| 共鸣         | 指物体因共振而发声的现象。即两个频率相同的物体，其中一个振动时，另一个也会振动发声。 |                                                              |



## 声音

声音实质是一种波，是由于物体振动对空气产生了挤压，使得空气也开始有节奏的振动，进而产生了**声波**。

声波有三要素：

* **频率：表示音阶的高低**。
  * 越高波长越短，所以低频波长较长，衰减较慢，传播的更远。高频则波长较短、衰减较快、从而传播更近。
  * 人听力的频率的范围一般是20Hz～20kHz。对 3～4kHz频率 范围内的声音比较敏感。
* **振幅：表示声音的响度**。
  * 一般用分贝(dB)来表示大小。越大则能量多大，声音越响。
* **波形：表示音色**。
  * 和材质有关，例如吉他和钢琴的音色就并不相同。

> 业界有个非常著名的等响曲线，它用来描述等响条件下声压级和声波频率的关系。
>
> 声压级较低时，低频高频的声音将会缺失，声压级越高则越符合听力的频率特征。



## 数字音频

一段音频波形数据 -> 采样(分割波形) -> 量化(01) -> 编码( 01) -> 数字信号

| 基础概念       |                                                              |                                                              |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 采样率         | xHZ的音频每个正弦波的采样次数 = 采样率/xHZ                   | 8k、16k、32k、44.1k、48k                                     |
| 采样大小       | 一个采样用多少bit存放。                                      | 常用16bit                                                    |
| 比特率（码率） | 用于衡量单位时间内音频数据的大小。这个音频数据是压缩编码压缩后数据量的多少。越大表示数据量越多，声音细节越精确。 | 计算一个PCM音频流的码率 :<br/>采样率 * 采样大小 * 声道数 <br/>8k * 16bit * 2 = 256kbps |
| 存储大小       | 可以根据码率来计算，一定时长的音频数据大小。                 | 码率 * 时间：<br />256kbps * 60s / 8 /1024 = 1.m85MB         |

### 采样和量化

**音频的采样就是在时间轴上对模拟信号进行数字化（A/D变换），即每秒采集多个次**。采样频率一般是44.1kHz。它是根据奈奎斯特定理来决定的，按比声音最高频率高2倍以上的频率对声音进行采样，这样就能够保证采样声音被数字化后依然保真。

> 为什么是2倍以上？
>
> 因为在现实中声音是连续的，而我们的采样数据并不是连续的还是离散的，相邻两份采样数据中间的声音是丢失，所以最少也需要在采样中间一份来贴近数据的变化。

**量化就是用一定位数的二进制信号来表示一个采样，进行数字化，也就是采样大小**。

例如16bit可以表示65535个数值，足够表示 44.1kHz 的采样数据。

以麦克风为例：麦克风内的碳膜会由于声波而受到挤压从而发生振动，振动过程中会接触电极，从而将声音信号转为了电信号。电极

### 编码

当对声音进行采样、量化之后就涉及到了采样数据如何存储的问题，而编码就是来解决这个问题的。

所以编码就是按照一定的格式**记录采样和量化后的数字数据**，可以是顺序存储、压缩存储等等。

直接采样的产生的数据量十分庞大，不适合网络传输，所以出现了很多压缩编码，它们使用压缩算法来压缩冗余信号。

**冗余信号**：人耳听觉范围之外的信号，以及被掩蔽掉的音频信号，主要是频域掩蔽效应与时域掩蔽效应。

* 人耳听觉范围之外的信号：(20~20000Hz)之外的无法识别的的音频信号。
* 被掩蔽掉的音频信号(频域遮蔽和时域遮蔽)。
  * 频域遮蔽：音量很低的声音。还有就是当声音的频率相差很近时, 音量大的将会覆盖音量小的。
  * 时域遮蔽：比如先有一个音量相对小一些的声音，同时进来了一个音量相对大的声音，音量大的声音持续一定时间，此时音量相对小的声音将会被屏蔽。相对小的继续发声，相对大的停止，屏蔽效果也仍然持续一定时间，需要过一会才能听见音量小的声音。

**压缩算法**：分为有损压缩和无损压缩。

* 无损压缩：解压后数据可以完全恢复。例如哈夫曼无损编码。
* 有损压缩：解压后数据会丢失部分，不能完全复原，从而导致部分失真。压缩比越小丢失的数据越多。

常见编码格式：

> 常见的音频编解码器有：OPUS、AAC、Vorbis、Speex、iLBC、AMR、G.711等

| 压缩编码格式                             | 说明                                                         | 适用场景                                                  |
| ---------------------------------------- | ------------------------------------------------------------ | --------------------------------------------------------- |
| PCM（Pulse Code Modulation）脉冲编码调制 | 一种裸数据格式，包括量化格式、采样率、声道数、数据比特率     |                                                           |
| WAV                                      | 基于PCM，在PCM前增加了44字节，用来描述采样率、声道数、数据格式等信息。音质非常好，大量软件都支持。 | 多媒体开发的中间文件、保存音乐和音效素材                  |
| MP3                                      | 音质在128Kbit/s以上表现还不错，兼容性好。压缩比比较高        | 适用于高比特率下对兼容性有要求的情况。                    |
| AAC                                      | 一种音频有损压缩技术                                         | 适用于128Kbit/s以下的音频编码，多用于视频中音频轨的编码。 |
| Ogg                                      | 可以用比MP3更小的码率实现比MP3更好的音质，不过兼容性较差。   | 适用于语音聊天的音频消息场景。                            |



## 图像

> 不同于美术中的 红黄蓝（品红色、黄色、青色）色料三原色。色光三原色 和 色料三原色互为补色。

一幅图像是由一个个像素点组成的，一个像素点都是通过**RGB**(即红绿蓝 三原色光)三个通道进行叠加来产生不同的颜色。

## 视频

视频是由一幅幅图像组成的。

### YUV/YCbCr

YUV 是一种彩色编码系统，主要是为了方便编码以及传输，并减少带宽占用和信息出错。同时YUV还向后兼容老式黑白电视。

在视频彩色视频信号的传输 是一种彩色编码系统，视频帧的裸数据更多使用的是YUV格式。

* `Y` 表示明亮度，也称灰阶值。仅有Y时就是黑白。
* `U(Cb)` 和 `V(Cr)` 表示的则是色度，用于描述影像的色彩及饱和度，即像素的颜色。
  * `U(Cb)`：饱和度，RGB输入信号 蓝色部分与RGB信号亮度值之间的差异。
  * `V(Cr)`：色调，RGB输入信号 红色部分与RGB信号亮度值之间的差异。

常用的采样格式有YUV444，YUV422，YUV420等。数字表示 在每行扫描线中各个分量之间的采样比例。

422 即Y:U:V = 4:2:2，表示四个像素中存在4个Y，2个U，2个V。所以每个像素采样Y，每两个像素采样一个UV。

其中YUV420比较特殊，并不是指没有V，而是指在一行中先每两个像素采样一个U，在下一行时每两个像素采集一个V，这样上下两行组成完整的UV，相当于2x2 的像素共用一个UV。

当然最终显示时YUV还是需要转换为RGB。



### 编码格式

设备的分辨率越高，所拥有的像素点就越多，从而数据量也就越大（一张图片在没有压缩的情况下基本都是MB级别的），所以出现了很多图像编码格式，例如JPEG等。

对于单个图像来说已经够用，不过对于视频来说，例如一般的24帧，每秒都有24张图像，仅使用这些图像编码格式依然时远远不够的，所以进而演变出了视频编码格式。它和音频编码类似，都是通过去除冗余数据来进行压缩。

* 帧间压缩：去除时间上的冗余。主要是利用视频数据前后之间存在极强的关联性。
* 帧内压缩：去除空间上的冗余。

常见的视频编码有：MPEG、H.264等

| 概念                           |                                              |                                                              |
| ------------------------------ | -------------------------------------------- | ------------------------------------------------------------ |
| I帧                            | 帧内编码帧；关键帧                           | 包含了帧的完整信息，解码时无需依赖其他帧。                   |
| P帧                            | 前向预测编码帧；压缩帧                       | 向前比较，依赖前面的帧                                       |
| B帧                            | 双向预测内插编码帧；压缩帧                   | 前后双向比较，依赖前面和后面的帧。                           |
| -                              |                                              |                                                              |
| IDR帧                          | H264中多帧预测的概念，IDR帧就是一种特殊的I帧 | 多帧预测中，I帧之后的P帧有可能会参考I帧之前的帧，所以设定IDR帧作为后面几帧的参考。 |
| GOP（Group Of Picture）        | MPEG所使用的一种视频压缩技术。               | 指两个关键帧之间的一组图片。                                 |
| DTS（Decoding Time Stamp）     | 解码时间戳                                   | 用于视频解码。告诉播放器该在什么时候解码这一帧的数据。       |
| PTS（Presentation Time Stamp） | 显示时间戳                                   | 用于解码阶段视频的同步和输出。告诉播放器该在什么时候显示这一帧的数据。 |
| SPS                            | 帧信息                                       |                                                              |
| PPS                            | 图像信息                                     |                                                              |

### IPB帧

I帧主要时去除空间上的冗余，PB帧主要去除时间上的冗余。

**I帧：帧内编码帧（intra picture)**

I帧也叫关键帧 通常是每个GOP的第一帧，它包含了帧的完整信息，可以当作是静态图像。对I帧进行压缩可以去除视频的空间冗余信息。

* 可以单独解码，解压后可以得到完整的图像。
* I帧一般可以作为随机访问的帧。

**P帧：前向预测编码帧（predictive-frame）**

它是通过将图像序列中前面已编码帧的时间冗余信息去除来达到压缩传输数据量的目的。

* 解码时需要依赖前面的I帧或者P帧才能得到一张完整的图像。

**B帧：双向预测内插编码帧（bi-directional interpolated prediction frame）**

和P帧的区别是 它即考虑源图像序列前面的已编码帧，又顾及源图像序列后面的已编码帧之间的时间冗余信息。

* 解码时需要参考其前一个I帧或者P帧及其后面的一个P帧才能得到一张完整的图像。



![image-20230412154106080](./%E9%9F%B3%E8%A7%86%E9%A2%91%E5%9F%BA%E7%A1%80.assets/image-20230412154106080.png)





## H.264编码原理

包含了多参考帧、多块类型、整数变换、帧内预测等压缩技术。

### NAL单元和码流结构

![NAL单元和码流结构](./%E9%9F%B3%E8%A7%86%E9%A2%91%E5%9F%BA%E7%A1%80.assets/image_1cei5f67b36fg48d341r5omv79.png)







## FFmpeg

|          |                                    |      |
| -------- | ---------------------------------- | ---- |
| AVPacket | 描述解码前或编码后的**压缩数据**。 |      |
| AVFrame  | 描述解码后或编码前的**原始数据**。 |      |
|          |                                    |      |



## 直播

泛娱乐直播拓扑架构
实时直播拓扑架构

### 直播常用的协议

* **HLS**协议：HTTP的流媒体协议，高延时（10s以上），跨平台性较好。
* **RTMP**协议：长连接，低延时（3s左右），网络穿透性差。

* **HDL**协议：RTMP协议的升级版，低延时（2s左右），网络穿透性好。

* **RTP**协议：低延时（1s以内），默认使用UDP作为传输协议。

非交互式场景可选 HLS 协议。交互式场景选择 HDL 或 RTMP协议。视频会议、连麦则可选RTP协议。

### 交互式直播场景

核心系统，基于 **流媒体服务（Live Server）**：

* 推流系统：主播使用推流系统将采集的视频和音频进行编码，并最终发送到流媒体服务器上。
* 拉流系统：用户端使用拉流系统将流媒体服务器上的视频资源进行播放。

其他系统，基于 **服务器模块（Http Server）**：

* 礼物系统：
* 支付系统：充值、提现等。
* 聊天系统：
* 社交系统：第三方登录、分享、关注列表、开播列表等。

## 拉流播放器

* 协议层处理：FFmpeg的 libavformat 模块。
* 解码得到原始数据：FFmpeg的 libavcodec 模块。
* 音视频渲染：OpenGL ES 相应API。
* 后处理增加清晰度：对比度调整、去块滤波器、锐化等效果器

## 相关工具和项目

|               |                                 |                                                              |
| ------------- | ------------------------------- | ------------------------------------------------------------ |
| AtomicParsley | 检测一个 MP4 的 moov 是否在前面 |                                                              |
| ijkplayer     | 支持边下边播开源播放器          | [bilibili/ijkplayer: Android/iOS video player based on FFmpeg n3.4, with MediaCodec, VideoToolbox support. (github.com)](https://github.com/bilibili/ijkplayer) |
| ExoPlayer     | 支持边下边播开源播放器          | [google/ExoPlayer: An extensible media player for Android (github.com)](https://github.com/google/ExoPlayer) |



## 搭建一个本地的流媒体服务

- 服务器(Linuex), 本地使用的mac
- 编译安装Nginx服务
- 配置RTMP服务并启动nginx


### Mac上安装Nginx 和 rtmp

1. 安装
```shell
brew install nginx-full --with-rtmp-module
```

2. rtmp 服务配置
```properties
# 修改配置文件 /usr/local/etc/nginx/nginx.conf

# rtmp服务
rtmp{
    server {
        # 指定服务器端口
        listen:1992;
        # 传输块大小 4000字节
        chunk_size:4000;
        # 指定流应用
        application live {
            live on;
            record off;
            allow play all;
        }
    }
}
```

3. 启动nginx
```shell
- nginx
- nginx -s reload
- nginx -s stop
```

### ffmpeg 命令

推流：

```shell
ffmpeg -re -i out.mp4 -c copy -f flv rtmp://server/xxx/xxx
```

拉流：

```shell
ffmpeg -i rtmp://server/xxx/xxx -c copy dump.flv
```

其他命令：

```shell
# -movflags faststart：将moov提前放到文件头部
ffmpeg -i input.mp4 -movflags faststart -acodec copy -vcodec copy output.mp4
```



### 本地调试

- 找一个直播地址 拉流 到本机rtmp服务器
```shell
ffmpeg -i http://xxxxx -c:a copy -c:v copy -f flv rtmp://localhost:1992/live/room
```
- ffplay 播放
```shell
ffplay rtmp://localhost:1992/live/room
```

